import os
import chromadb
from langchain.retrievers.merger_retriever import MergerRetriever
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceBgeEmbeddings
from langchain_community.document_transformers import (EmbeddingsRedundantFilter,EmbeddingsClusteringFilter,)
from langchain.retrievers.document_compressors import DocumentCompressorPipeline
from langchain.retrievers import ContextualCompressionRetriever
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Part 1 : Get the Embedding Model
model_name = "BAAI/bge-large-en"
model_kwargs = {'device': 'cpu'}
encode_kwargs = {'normalize_embeddings': False}
hf = HuggingFaceBgeEmbeddings(
    model_name=model_name,
    model_kwargs=model_kwargs,
    encode_kwargs=encode_kwargs
)

# Part 2 : Data Preprocessing
loader_un_sdg = PyPDFLoader("data/000885.pdf")
documents_un_sdg = loader_un_sdg.load()
text_splitter_un_sdg = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
texts_un_sdg = text_splitter_un_sdg.split_documents(documents_un_sdg)

loader_paris_agreement = PyPDFLoader("data/000945.pdf")
documents_paris_agreement = loader_paris_agreement.load()
text_splitter_paris_agreement = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
texts_paris_agreement = text_splitter_paris_agreement.split_documents(documents_paris_agreement)

# Part 3 : Create and vector_space Vectors
un_sdg_vector_space = Chroma.from_documents(texts_un_sdg, hf, collection_metadata={"hnsw:space": "cosine"}, persist_directory="vector_space/un_sdg_chroma_cosine")
paris_agreement_vector_space = Chroma.from_documents(texts_paris_agreement, hf, collection_metadata={"hnsw:space": "cosine"}, persist_directory="vector_space/paris_chroma_cosine")

# Part 4 : Load Vector vector_space
load_un_sdg_vector_space = Chroma(persist_directory="vector_space/un_sdg_chroma_cosine", embedding_function=hf)
load_paris_agreement_vector_space = Chroma(persist_directory="vector_space/paris_chroma_cosine", embedding_function=hf)

# Part 5 : Init Merge Retriever
retriever_un_sdg = load_un_sdg_vector_space.as_retriever(search_type = "similarity", search_kwargs = {"k":3})
retriever_paris_agreement = load_paris_agreement_vector_space.as_retriever(search_type = "similarity", search_kwargs = {"k":3})
lotr = MergerRetriever(retrievers=[retriever_un_sdg, retriever_paris_agreement])

for chunks in lotr.get_relevant_documents("marine protected areas are being designated according which approaches?"):
    print(chunks.page_content)

